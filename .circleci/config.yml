# These environment variables must be set in CircleCI UI
#
# DOCKERHUB_REPO - docker hub repo, format: <username>/<repo>
# DOCKER_USER    - login info for docker hub
# DOCKER_PASS
# COVERALLS_REPO_TOKEN - used by coveralls-python
#
version: 2.1
orbs:
  # https://circleci.com/developer/orbs/orb/circleci/node
  node: circleci/node@7.0.0
  # https://circleci.com/developer/orbs/orb/circleci/python
  python: circleci/python@2.1.1

executors:
  # Using executors so most of the version information is here
  # CircleCI Documentation:
  # https://circleci.com/docs/reusing-config/#authoring-reusable-executors
  # https://circleci.com/docs/configuration-reference/#executors
  # https://circleci.com/docs/configuration-reference/#docker
  # https://circleci.com/docs/circleci-images/
  # https://circleci.com/docs/introduction-to-yaml-configurations/#anchors-and-aliases
  base:
    docker:
      # https://circleci.com/developer/images/image/cimg/base
      - image: cimg/base:<<parameters.cimg_version>><<parameters.ubuntu_version>>
        auth: &default_auth
          username: $DOCKER_USER
          password: $DOCKER_PASS
    parameters:
      cimg_version:
        description: "CircleCI version tag"
        default: "current"
        type: enum
        # current - Latest production ready base image, updated monthly
        # edge - Lastest HEAD base image
        # <YYYY.MM> - The monthly snapshot, used for the most deterministic builds.
        enum: ["current", "edge", "2024.02", "2024.01"]
      ubuntu_version:
        description: "optional Ubuntu version"
        default: ""
        type: enum
        # For current supported Ubuntu versions, see:
        # https://circleci.com/developer/images/image/cimg/base
        enum: ["", "-20.04", "-22.04"]
  node:
    # https://circleci.com/developer/images/image/cimg/node
    docker:
      - image: cimg/node:<<parameters.node_version>>
        auth: *default_auth
    parameters:
      node_version:
        description: "version tag"
        default: "18.20"
        type: string
  python:
    # https://circleci.com/developer/images/image/cimg/python
    docker:
      - image: cimg/python:<<parameters.python_version>><<parameters.variant>>
        auth: *default_auth
    parameters: &python_parameters
      python_version:
        description: "python version tag"
        default: "3.11.8"
        type: string
      variant:
        description: "image variant"
        default: ""
        type: enum
        enum: ["", "-node", "-browsers"]
      postgres_version:
        description: "postgres version tag"
        default: "14.13"
        type: string
  python_with_postgres:
    # https://circleci.com/developer/images/image/cimg/python
    # https://circleci.com/developer/images/image/cimg/postgres
    docker:
      - image: cimg/python:<<parameters.python_version>><<parameters.variant>>
        auth: *default_auth
        environment:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: secret-<<pipeline.id>>
          POSTGRES_DB: circle
      - image: cimg/postgres:<<parameters.postgres_version>>
        auth: *default_auth
        environment:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: secret-<<pipeline.id>>
          POSTGRES_DB: circle
    parameters:
      <<: *python_parameters
  ruby:
    # https://circleci.com/developer/images/image/cimg/ruby
    docker:
      - image: cimg/ruby:<<parameters.ruby_version>>
        auth: *default_auth
    parameters:
      ruby_version:
        description: "version tag"
        default: "2.7.2"
        type: string

commands:
  checkout_with_submodules:
    description: Checkout Relay code and submodules
    steps:
      - checkout
      - run: git submodule sync
      - run: git submodule update --init

jobs:
  build_frontend:
    executor:
      name: base
    working_directory: "/home/circleci/backend-project"
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - checkout_with_submodules
      - setup_remote_docker:
          docker_layer_caching: True
      - run:
          name: Build Docker image
          command: |
            docker build --target frontend --tag fx-private-relay .
      - run:
          name: docker save fx-private-relay
          command: |
            mkdir --parents /tmp/workspace;
            docker save --output /tmp/workspace/docker.tar "fx-private-relay"
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - docker.tar
  test_frontend:
    executor:
      name: base
    steps:
      - setup_remote_docker:
          docker_layer_caching: True
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Restore Docker image cache
          command: docker load --input /tmp/workspace/docker.tar
      - run:
          name: Check licences of frontend dependencies
          command: |
            docker run \
              --entrypoint "/bin/bash" \
              fx-private-relay \
              -c \
                'npm run licensecheck --workspace frontend'
      - run:
          name: Lint Code
          command: |
            docker run \
              --entrypoint "/bin/bash" \
              fx-private-relay \
              -c \
                'npm run lint --workspace frontend -- --max-warnings=0'
      - run:
          name: Test Code
          command: |
            # Create a volume
            docker run \
              --volume /tmp/workspace \
              --name workspace-test-results \
              alpine \
              /bin/sh -c \
                "chmod 0777 /tmp/workspace && \
                 chown 10001:10001 /tmp/workspace"
            # Actually run test
            set +e
            docker run \
              --entrypoint "/bin/bash" \
              --volumes-from workspace-test-results \
              fx-private-relay \
              -c \
                'npm test --workspace frontend -- \
                  --ci \
                  --runInBand \
                  --coverageDirectory=/tmp/workspace/test-results/frontend-coverage ; \
                  STATUS=$?
                  mkdir --parents /tmp/workspace/test-results/frontend
                  mv /home/node/frontend/junit.xml /tmp/workspace/test-results/frontend/junit.xml ; \
                  exit $STATUS'
            TEST_STATUS=$?
            set -e
            # Copy results to local disk
            mkdir --parents /tmp/workspace/
            docker cp workspace-test-results:/tmp/workspace/test-results /tmp/workspace
            # Exit with test error code
            exit $TEST_STATUS
      - store_test_results:
          path: /tmp/workspace/test-results/frontend/junit.xml
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - test-results/frontend-coverage


  convert_frontend_coverage:
    executor: ruby
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - checkout
      - run: gem install coveralls-lcov
      - run:
          name: Add frontend prefix to lcov.info
          command: |
            sed 's|^SF:|SF:frontend/|' \
              /tmp/workspace/test-results/frontend-coverage/lcov.info \
              > /tmp/workspace/test-results/frontend-coverage/lcov-prefixed.info
      - run:
          name: Generate coveralls.json report
          command: |
            coveralls-lcov \
              --verbose --dry-run \
              /tmp/workspace/test-results/frontend-coverage/lcov-prefixed.info \
              > /tmp/workspace/test-results/frontend-coverage/coveralls.json
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - test-results/frontend-coverage/lcov-prefixed.info
            - test-results/frontend-coverage/coveralls.json

  build_test_backend:
    executor:
      name: base
    working_directory: "/home/circleci/backend-project"
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - checkout_with_submodules
      - setup_remote_docker:
          docker_layer_caching: True
      - run:
          name: Restore Docker image cache
          command: docker load --input /tmp/workspace/docker.tar
      - run:
          name: Create a version.json
          command: |
            # create a version.json per https://github.com/mozilla-services/Dockerflow/blob/master/docs/version_object.md
            printf '{"commit":"%s","version":"%s","source":"https://github.com/%s/%s","build":"%s"}\n' \
            "$CIRCLE_SHA1" \
            "$CIRCLE_TAG" \
            "$CIRCLE_PROJECT_USERNAME" \
            "$CIRCLE_PROJECT_REPONAME" \
            "$CIRCLE_BUILD_URL" > version.json

      - run:
          name: Build Docker image
          command: |
            docker build --tag fx-private-relay \
            --build-arg CIRCLE_BRANCH="$CIRCLE_BRANCH" \
            --build-arg CIRCLE_TAG="$CIRCLE_TAG" \
            --build-arg CIRCLE_SHA1="$CIRCLE_SHA1" \
            .

      - run:
          name: Test Code
          command: |
            # Create a volume owned by the app user
            docker run \
              --volume /tmp/workspace \
              --name workspace-test-results \
              alpine \
              /bin/sh -c \
                "chmod 0777 /tmp/workspace && \
                 chown 10001:10001 /tmp/workspace"

            # Run coverage tests, outputting the results in XML format, capture exit code
            set +e
            docker run \
              --entrypoint "/bin/bash" \
              --volumes-from workspace-test-results \
              -e PHONES_ENABLED=$PHONES_ENABLED \
              fx-private-relay \
              -c \
                'mkdir --parents /tmp/workspace/test-results/pytest && \
                 mkdir --parents /tmp/workspace/test-results/backend-coverage && \
                 /app/.local/bin/pytest \
                   --cov=. \
                   --cov-config=.coveragerc \
                   --cov-report=term-missing \
                   --cov-report=xml \
                   --cov-fail-under=60 \
                   --cov-branch \
                   --junitxml=/tmp/workspace/test-results/pytest/results.xml ; \
                 STATUS=$?
                 mv coverage.xml /tmp/workspace/test-results/backend-coverage/results.xml ; \
                 mv .coverage /tmp/workspace/test-results/backend-coverage/.coverage; \
                 exit $STATUS'
            TEST_STATUS=$?
            set -e

            # Copy results to local disk
            mkdir --parents /tmp/workspace/
            docker cp workspace-test-results:/tmp/workspace/test-results /tmp/workspace

            # Exit with test error code
            exit $TEST_STATUS

      - store_test_results:
          path: /tmp/workspace/test-results/pytest

      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - test-results/pytest
            - test-results/backend-coverage

      - run:
          name: Check if deploying
          command: |
            if [ "${CIRCLE_BRANCH}" != "main" ] && [ -z "${CIRCLE_TAG}" ]; then
              echo "Skipping exporting Docker image, not main branch or tag."
              circleci step halt
            fi
            # https://stackoverflow.com/a/18558871/10612
            if case $CIRCLE_TAG in addon-*) ;; *) false;; esac; then
              echo "Skipping exporting Docker image, ${CIRCLE_TAG} has addon- prefix."
              circleci step halt
            fi

      # save the built docker container into CircleCI's cache. This is
      # required since Workflows do not have the same remote docker instance.
      - run:
          name: docker save fx-private-relay
          command: |
            mkdir --parents /tmp/workspace;
            docker save --output /tmp/workspace/docker.tar "fx-private-relay"
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - docker.tar

  upload_coverage:
    executor:
      name: python
      variant: "-node"
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - checkout
      - run:
          name: Upload coverage
          command: |
            pip install coveralls
            cp /tmp/workspace/test-results/backend-coverage/.coverage .
            coveralls --merge=/tmp/workspace/test-results/frontend-coverage/coveralls.json

  deploy:
    executor:
      name: base
    steps:
      - setup_remote_docker:
          docker_layer_caching: True
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Restore Docker image cache
          command: docker load --input /tmp/workspace/docker.tar

      - run:
          name: Deploy to Dockerhub
          command: |
            echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin
            # deploy master
            if [ "${CIRCLE_BRANCH}" == "main" ]; then
              docker tag fx-private-relay ${DOCKERHUB_REPO}:latest
              docker push ${DOCKERHUB_REPO}:latest
            elif  [ ! -z "${CIRCLE_TAG}" ]; then
            # deploy a release tag...
              echo "${DOCKERHUB_REPO}:${CIRCLE_TAG}"
              docker tag fx-private-relay "${DOCKERHUB_REPO}:${CIRCLE_TAG}"
              docker images
              docker push "${DOCKERHUB_REPO}:${CIRCLE_TAG}"
            fi

  # python_job is a generic job for Python and Django tests
  # It avoids duplicating code and forgetting to duplicate fixes
  # It uses functions defined in python_job.bash
  # Section 1: Prepare environment
  # Section 2: Setup optional steps
  # Section 3: Run the command
  # Section 4: Save results
  python_job:
    executor:
      name: << parameters.executor >>
      postgres_version: << parameters.postgres_version >>
      python_version: << parameters.python_version >>
      variant: << parameters.variant >>
    parameters:
      <<: *python_parameters
      allow_fail:
        description: "Allow the command to fail without failing job."
        type: boolean
        default: false
      command:
        description: "What command should the job run?"
        default: "pytest"
        type: enum
        enum: ["pytest", "black", "mypy", "build_email_tracker_lists", "build_glean", "check_glean", "ruff"]
      executor:
        description: "Which executor to use?"
        default: python
        type: enum
        enum: ["python", "python_with_postgres"]
      mypy_strict:
        description: "mypy will use --strict"
        type: boolean
        default: false
      production_with_new_migrations:
        description: "Test if deployed code will work with new migrations."
        type: boolean
        default: false
      pytest_fail_fast:
        description: "pytest will stop after 3 failures"
        type: boolean
        default: false
      pytest_phones_backend:
        description: "Enable phones with Twilio"
        default: "twilio"
        type: enum
        enum: ["no-phones", "twilio"]
      test_results_filename:
        description: "What is the name of the jUnit XML test output? (Optional)"
        default: ""
        type: string
      update_dependency:
        description: "Update a dependency before running the command (Optional)"
        default: ""
        type: string
    steps:
      # Section 1: Prepare environment
      - checkout_with_submodules
      - python/install-packages:
          pkg-manager: pip
      - run:
          name: Setup Bash Environment
          # This command uses the "mustache section" syntax, somewhat documented here:
          # https://support.circleci.com/hc/en-us/articles/4417604103835-Using-Mustache-Conditionals-in-Config-File
          # It looks like:
          # echo "Let's be <<# parameters.very_careful >>VERY <</ parameters.very_careful >>careful"
          # If "very_careful" is truthy, this becomes:
          # echo "Let's be VERY careful"
          # If "very_careful" is falsy, this becomes:
          # echo "Let's be careful"
          # TODO: Convert to when / unless syntax, which is better documented, but may be uglier...
          command: |
            # set -x  # Uncomment to debug
            TMP_ENV=$(mktemp)

            if [ "<<# parameters.allow_fail >>allow_fail<</ parameters.allow_fail >>" == "allow_fail" ]
            then
              ALLOW_FAILURE=1
            else
              ALLOW_FAILURE=0
            fi
            echo "export ALLOW_FAILURE=${ALLOW_FAILURE}" >> "$TMP_ENV"

            if [ "twilio" == "<< parameters.pytest_phones_backend >>" ]
            then
              PHONES_ENABLED=1
            else
              PHONES_ENABLED=0
            fi
            echo "export PHONES_ENABLED=${PHONES_ENABLED}" >> "$TMP_ENV"

            if [ "<<# parameters.mypy_strict >>mypy_strict<</ parameters.mypy_strict >>" == "mypy_strict" ]
            then
              MYPY_STRICT=1
            else
              MYPY_STRICT=0
            fi
            echo "export MYPY_STRICT=${MYPY_STRICT}" >> "$TMP_ENV"

            if [ "<<# parameters.pytest_fail_fast >>pytest_fail_fast<</ parameters.pytest_fail_fast >>" == "pytest_fail_fast" ]
            then
              PYTEST_FAIL_FAST=1
            else
              PYTEST_FAIL_FAST=0
            fi
            echo "export PYTEST_FAIL_FAST=${PYTEST_FAIL_FAST}" >> "$TMP_ENV"

            if [ "<<# parameters.production_with_new_migrations >>production_with_new_migrations<</ parameters.production_with_new_migrations >>" == "production_with_new_migrations" ]
            then
              PYTEST_MIGRATIONS_MODE=1
            else
              PYTEST_MIGRATIONS_MODE=0
            fi
            echo "export PYTEST_MIGRATIONS_MODE=${PYTEST_MIGRATIONS_MODE}" >> "$TMP_ENV"

            TEST_RESULTS_FILENAME="<< parameters.test_results_filename >>"
            echo "export TEST_RESULTS_FILENAME=$(printf '%q' "${TEST_RESULTS_FILENAME}")" >> "$TMP_ENV"

            if [ "python_with_postgres" == "<<parameters.executor>>" ]
            then
              DATABASE_URL="postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@localhost/${POSTGRES_DB}"
              TEST_DB_NAME="test_${POSTGRES_DB}"
              TEST_DB_URL="postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@localhost/${TEST_DB_NAME}"
              DATABASE_ENGINE="postgres"
            else
              DATABASE_URL="sqlite:///db.sqlite3"
              TEST_DB_NAME="test.sqlite3"
              TEST_DB_URL="sqlite:///${TEST_DB_NAME}"
              DATABASE_ENGINE="sqlite"
            fi
            echo "export DATABASE_URL=$(printf '%q' "${DATABASE_URL}")" >> "$TMP_ENV"
            echo "export TEST_DB_NAME=$(printf '%q' "${TEST_DB_NAME}")" >> "$TMP_ENV"
            echo "export TEST_DB_URL=$(printf '%q' "${TEST_DB_URL}")" >> "$TMP_ENV"
            echo "export DATABASE_ENGINE=$(printf '%q' "${DATABASE_ENGINE}")" >> "$TMP_ENV"
            echo "export TEST_RESULTS_DIR=job-results" >> "$TMP_ENV"

            cat "$TMP_ENV" | tee --append "$BASH_ENV"
            cat /home/circleci/project/.circleci/python_job.bash >> "$BASH_ENV"
            rm "$TMP_ENV"
      - unless:
          condition:
            equal: ["", << parameters.test_results_filename >>]
          steps:
            - run:
                name: Create job-results directory
                command: mkdir -p "$TEST_RESULTS_DIR"
      - run:
          name: Set test defaults
          command: cp .env-dist .env
      - run:
          name: Create empty staticfiles directories
          command: |
            mkdir -p staticfiles
            mkdir -p frontend/out
      # Section 2: Setup optional steps
      # Setup postgres, if selected
      # This is done later in the process to give the postgres image more time to boot up.
      - when:
          condition:
            equal: ["python_with_postgres", << parameters.executor >>]
          steps:
            - run:
                name: Install dockerize
                command: install_dockerize v0.6.1
            - run:
                name: Wait for the database
                command: wait_for_the_database
      - when:
          condition:
            and:
              - << parameters.production_with_new_migrations >>
              - equal: [ "python", << parameters.executor >> ]
          steps:
            - run:
                name: Install sqlite3
                command: sudo apt-get update && sudo apt-get install -y sqlite3
      # Setup migrations test, if selected
      - when:
          condition: << parameters.production_with_new_migrations >>
          steps:
            - run:
                name: Run tests, keep branch test database
                command: run_pytest --skip-results --create-db
            - run:
                name: Show latest migrations on branch
                command: show_migrations
            - run:
                name: Switch to production tag, production requirements
                command: switch_to_production
      # Update dependency, if selected
      - unless:
          condition:
            equal: [ "", << parameters.update_dependency >> ]
          steps:
            - run:
                name: "Update dependency << parameters.update_dependency >>"
                command: pip install --pre --upgrade "<< parameters.update_dependency >>"
      # Section 3: Run the command
      - run:
          name: Run << parameters.command >><<# parameters.allow_fail >> (failure allowed)<</ parameters.allow_fail >> 
          command: run_command << parameters.command >>
      - when:
          condition: << parameters.production_with_new_migrations >>
          steps:
            - run:
                name: Show migrations after tests
                command: show_migrations
      # Section 4: Save results
      - unless:
          condition:
            equal: ["", << parameters.test_results_filename >>]
          steps:
            - store_test_results:
                path: job-results

workflows:
  version: 2
  build-test-deploy:
    jobs:
      - build_frontend:
          filters: &default_filters
            tags:
              only: /.*/
      - build_test_backend:
          requires:
            - build_frontend
          filters: *default_filters

      - python_job:
          name: black style check
          command: black
          filters: *default_filters

      - python_job:
          name: ruff linting check
          command: ruff
          test_results_filename: "ruff.xml"
          filters: *default_filters

      - python_job:
          name: mypy type check
          command: mypy
          test_results_filename: "mypy.xml"
          filters: *default_filters

      - python_job:
          name: mypy strict type check
          command: mypy
          allow_fail: true
          mypy_strict: true
          test_results_filename: "mypy-strict.xml"
          filters: *default_filters

      - python_job:
          name: pytest with current postgres
          command: pytest
          executor: "python_with_postgres"
          test_results_filename: "pytest-postgres.xml"
          filters: *default_filters

      - python_job:
          name: pytest with postgres << matrix.postgres_version >>
          command: pytest
          matrix:
            parameters:
              postgres_version: ["17.5"]
          executor: python_with_postgres
          test_results_filename: "pytest-postgres-<< matrix.postgres_version >>.xml"
          filters: *default_filters

      - python_job:
          name: sqlite migrations test
          command: pytest
          production_with_new_migrations: true
          pytest_fail_fast: true
          test_results_filename: "sqlite3-migrations.xml"
          filters: *default_filters

      - python_job:
          name: postgres migrations test
          command: pytest
          executor: "python_with_postgres"
          production_with_new_migrations: true
          pytest_fail_fast: true
          test_results_filename: "postgres-migrations.xml"
          filters: *default_filters

      - python_job:
          name: python test phones disabled
          command: pytest
          pytest_phones_backend: no-phones
          test_results_filename: pytest-phones-disabled.xml
          filters: *default_filters

      - python_job:
          name: django 5.0 test
          command: pytest
          allow_fail: true
          pytest_fail_fast: true
          test_results_filename: pytest-django-5-0.xml
          update_dependency: "Django>=5.0,<5.1"
          filters: *default_filters

      - python_job:
          name: python 3.12 test
          python_version: "3.12.7"
          command: pytest
          test_results_filename: pytest-python-3-12.xml
          filters: *default_filters

      - python_job:
          name: python 3.13 test
          python_version: "3.13"
          allow_fail: true
          command: pytest
          pytest_fail_fast: true
          test_results_filename: pytest-python-3-13.xml
          filters: *default_filters

      - python_job:
          name: check generated glean_parser files
          command: check_glean
          filters: *default_filters

      - test_frontend:
          requires:
            - build_frontend
          filters: *default_filters

      - convert_frontend_coverage:
          requires:
            - test_frontend
          filters: *default_filters

      - upload_coverage:
          requires:
            - convert_frontend_coverage
            - build_test_backend
          filters: *default_filters

      - deploy:
          requires:
            - build_test_backend
          filters:
            tags:
              ignore: /addon-.*/
            branches:
              only: main
